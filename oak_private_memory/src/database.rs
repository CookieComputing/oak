//
// Copyright 2025 The Project Oak Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
use std::collections::HashMap;

use anyhow::{bail, ensure};
use async_trait::async_trait;
use bincode::{config, Decode, Encode};
use prost::Message;
use rand::Rng;
use sealed_memory_grpc_proto::oak::private_memory::sealed_memory_database_service_client::SealedMemoryDatabaseServiceClient;
use sealed_memory_rust_proto::oak::private_memory::{
    DataBlob, Memory, ReadDataBlobRequest, WriteDataBlobRequest,
};
use tempfile::tempdir;
use tonic::transport::Channel;

use crate::{
    debug,
    encryption::{decrypt, encrypt, generate_nonce},
};
pub type ExternalDbClient = SealedMemoryDatabaseServiceClient<Channel>;
// The unique id for a opaque blob stored in the disk.
// TODO: b/413429146 - Use a larger int.
pub type BlobId = i64;

// The unique id for a memory, responding to `struct Memory`.
// It doesn't have a 1:1 mapping to BlobId, as a single memory
// might result in multiple blobs. For example, the raw content
// of a memory becomes a blob, while the meta data becomes another.
// The memory id is generated by the server and returned to clients
// at `add_memory` requests. Clients then can use this id to get the
// memory.
pub type MemoryId = String;

/// The essential database that stores all the meta information
/// except the raw document content of a user.
///
/// The current schema is
/// {
///   "memory_id": string, indexable
///   "tags": repeated string, indexable
///   "blob_id": string
/// }
/// Indexable fields are the ones that can be searched against.
pub struct IcingMetaDatabase {
    icing_search_engine: cxx::UniquePtr<icing::IcingSearchEngine>,
    base_dir: String,
}

// `IcingMetaBase` is safe to send because it is behind a unique_ptr,
// but it is unsafe to sync because that will allow concurrent write accesses
// to the underlying icing database.
unsafe impl Send for IcingMetaDatabase {}
impl !Sync for IcingMetaDatabase {}

const NAMESPACE_NAME: &str = "namespace";
const SCHMA_NAME: &str = "Memory";
const TAG_NAME: &str = "tag";
const MEMORY_ID_NAME: &str = "memoryId";
const BLOB_ID_NAME: &str = "blobId";

impl IcingMetaDatabase {
    /// Rebuild the icing database in `target_base_dir` given the content of the
    /// ground truth files in `buffer`.
    pub fn import(buffer: &[u8], target_base_dir: Option<&str>) -> anyhow::Result<Self> {
        let base_dir_str = match target_base_dir {
            Some(dir) => dir.to_string(),
            _ => {
                let temp_dir = tempdir()?;
                temp_dir.path().to_str().unwrap().to_string()
            }
        };

        // Decode the ground truth data
        let ground_truth = icing::IcingGroundTruthFiles::decode_from_slice(buffer)?;

        // Migrate the data to the target directory (this handles cleaning the
        // directory)
        ground_truth.migrate(&base_dir_str)?;

        // Initialize Icing Search Engine from the migrated directory
        let options_bytes = icing::get_default_icing_options(&base_dir_str).encode_to_vec();
        let icing_search_engine = icing::create_icing_search_engine(&options_bytes);
        let result_proto = icing_search_engine.initialize();
        if result_proto.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into()) {
            bail!("Failed to initialize Icing engine after import: {:?}", result_proto.status);
        }

        Ok(Self { icing_search_engine, base_dir: base_dir_str })
    }

    /// Create a new icing database in `base_dir`. If there is already a icing
    /// db in `base_dir`, the old one will be deleted.
    pub fn new(base_dir: &str) -> anyhow::Result<Self> {
        let schema_type_builder = icing::create_schema_type_config_builder();
        schema_type_builder
            .set_type(SCHMA_NAME.as_bytes())
            .add_property(
                icing::create_property_config_builder()
                    .set_name(TAG_NAME.as_bytes())
                    .set_data_type_string(
                        icing::term_match_type::Code::ExactOnly.into(),
                        icing::string_indexing_config::tokenizer_type::Code::Plain.into(),
                    )
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Repeated.into(),
                    ),
            )
            .add_property(
                icing::create_property_config_builder()
                    .set_name(MEMORY_ID_NAME.as_bytes())
                    .set_data_type_string(
                        icing::term_match_type::Code::ExactOnly.into(),
                        icing::string_indexing_config::tokenizer_type::Code::Plain.into(),
                    )
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Required.into(),
                    ),
            )
            .add_property(
                icing::create_property_config_builder()
                    .set_name(BLOB_ID_NAME.as_bytes())
                    // We don't need to index blob id
                    .set_data_type(icing::property_config_proto::data_type::Code::Int64.into())
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Required.into(),
                    ),
            );

        let schema_builder = icing::create_schema_builder();
        schema_builder.add_type(&schema_type_builder);
        let schema = schema_builder.build();

        let options_bytes = icing::get_default_icing_options(base_dir).encode_to_vec();
        let icing_search_engine = icing::create_icing_search_engine(&options_bytes);
        let result_proto = icing_search_engine.initialize();
        ensure!(result_proto.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));

        let result_proto = icing_search_engine.set_schema(&schema);
        ensure!(result_proto.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));

        Ok(Self { icing_search_engine, base_dir: base_dir.to_string() })
    }

    pub fn add_memory(&mut self, memory: Memory, blob_id: BlobId) -> anyhow::Result<()> {
        let memory_id = memory.id;
        let tags: Vec<&[u8]> = memory.tags.iter().map(|x| x.as_bytes()).collect();
        let doc = icing::create_document_builder()
            .set_key(NAMESPACE_NAME.as_bytes(), memory_id.as_bytes())
            .set_schema(SCHMA_NAME.as_bytes())
            .add_string_property(TAG_NAME.as_bytes(), &tags)
            .add_string_property(MEMORY_ID_NAME.as_bytes(), &[memory_id.as_bytes()])
            .add_int64_property(BLOB_ID_NAME.as_bytes(), blob_id)
            .build();
        let result = self.icing_search_engine.put(&doc);
        if result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into()) {
            debug!("{:?}", result);
        }
        ensure!(result.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));
        Ok(())
    }

    pub fn get_memories_by_tag(&self, tag: String) -> anyhow::Result<Vec<BlobId>> {
        let mut search_spec = icing::SearchSpecProto::default();
        search_spec.query = Some(tag);
        // Match exactly as defined in the schema for tags.
        search_spec.term_match_type = Some(icing::term_match_type::Code::ExactOnly.into());
        // Only search within the 'tag' property.
        let mut filter = icing::TypePropertyMask::default();
        filter.schema_type = Some(SCHMA_NAME.to_string());
        filter.paths.push(TAG_NAME.to_string());
        search_spec.type_property_filters.push(filter);

        let mut result_spec = icing::ResultSpecProto::default();
        // Request a large number to get all results in one go for simplicity.
        // Consider pagination for very large datasets.
        result_spec.num_per_page = Some(1000);
        // Only retrieve the blob_id property.
        let mut projection = icing::TypePropertyMask::default();
        projection.schema_type = Some(SCHMA_NAME.to_string());
        projection.paths.push(BLOB_ID_NAME.to_string());
        result_spec.type_property_masks.push(projection);

        let search_result: icing::SearchResultProto = self.icing_search_engine.search(
            &search_spec,
            &icing::get_default_scoring_spec(), // Use default scoring for now
            &result_spec,
        );

        if search_result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into())
        {
            bail!("Icing search failed: {:?}", search_result.status);
        }

        Ok(search_result
            .results
            .into_iter()
            .filter_map(|doc_hit| {
                doc_hit
                    .document?
                    .properties
                    .into_iter()
                    .find(|prop| prop.name == Some(BLOB_ID_NAME.to_string()))?
                    .int64_values
                    .first()
                    .cloned()
            })
            .collect::<Vec<_>>())
    }

    pub fn get_blob_id_by_memory_id(&self, memory_id: MemoryId) -> anyhow::Result<Option<BlobId>> {
        let mut search_spec = icing::SearchSpecProto::default();
        search_spec.query = Some(memory_id.to_string());
        search_spec.term_match_type = Some(icing::term_match_type::Code::ExactOnly.into());

        // Filter by schema type
        let mut filter = icing::TypePropertyMask::default();
        filter.schema_type = Some(SCHMA_NAME.to_string());
        // Optionally, restrict the query to the memoryId property if the query syntax
        // above isn't specific enough
        filter.paths.push(MEMORY_ID_NAME.to_string());
        search_spec.type_property_filters.push(filter);

        let mut result_spec = icing::ResultSpecProto::default();
        result_spec.num_per_page = Some(1); // We expect at most one result
                                            // Only retrieve the blob_id property.
        let mut projection = icing::TypePropertyMask::default();
        projection.schema_type = Some(SCHMA_NAME.to_string());
        projection.paths.push(BLOB_ID_NAME.to_string());
        result_spec.type_property_masks.push(projection);

        let search_result: icing::SearchResultProto = self.icing_search_engine.search(
            &search_spec,
            &icing::get_default_scoring_spec(), // Scoring doesn't matter much here
            &result_spec,
        );

        if search_result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into())
        {
            bail!("Icing search failed for memory_id {}: {:?}", memory_id, search_result.status);
        }

        // Extract the blob_id (int64) from the first result, if any
        Ok(search_result.results.first().and_then(|doc_hit| {
            doc_hit
                .document
                .as_ref()?
                .properties
                .iter()
                .find(|prop| prop.name == Some(BLOB_ID_NAME.to_string()))?
                .int64_values
                .first()
                .cloned()
        }))
    }

    pub fn export(&self) -> Vec<u8> {
        self.icing_search_engine.persist_to_disk(icing::persist_type::Code::Full.into());
        let blob = icing::IcingGroundTruthFiles::new(&self.base_dir)
            .expect("Failed to read ground truth files from base_dir")
            .encode_to_vec()
            .expect("Export encoding failed");
        debug!("Exporting icing db, len: {}", blob.len());
        blob
    }

    pub fn reset(&self) {
        self.icing_search_engine.reset();
    }
}

impl Drop for IcingMetaDatabase {
    fn drop(&mut self) {
        self.icing_search_engine.persist_to_disk(icing::persist_type::Code::Full.into());
    }
}

/// In memory cache for memories. When a memory is added, it is cached in
/// `MemoryCache` and also persisted at disk. When a memory is fetched, if the
/// memory is cached, it is returned directly from the cached. Otherwise, it
/// will further fetched from the external storage.
// TODO: b/412698203 - Add eviction to avoid OOM.
pub struct MemoryCache {
    db_client: ExternalDbClient,
    content_cache: HashMap<BlobId, Memory>,
    dek: Vec<u8>,
}

impl MemoryCache {
    pub fn new(db_client: ExternalDbClient, dek: Vec<u8>) -> Self {
        let content_cache = HashMap::<BlobId, Memory>::default();
        Self { db_client, dek, content_cache }
    }

    pub async fn get_memory_by_blob_id(&mut self, blob_id: &BlobId) -> anyhow::Result<Memory> {
        // Check cache first
        if let Some(memory) = self.content_cache.get(blob_id) {
            return Ok(memory.clone());
        }

        // If not in cache, fetch from external DB
        let encrypted_blob = self.db_client.get_blob(blob_id).await?;
        let decrypted_data = decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
        let memory: Memory = Memory::decode(&*decrypted_data)?;
        self.content_cache.insert(*blob_id, memory.clone());
        Ok(memory)
    }

    pub async fn get_memories_by_blob_ids(
        &mut self,
        blob_ids: &[BlobId],
    ) -> anyhow::Result<Vec<Memory>> {
        let mut results: HashMap<BlobId, Memory> = HashMap::with_capacity(blob_ids.len());
        let mut missing_ids: Vec<BlobId> = Vec::new();

        // Check cache first
        for blob_id in blob_ids {
            if let Some(memory) = self.content_cache.get(blob_id) {
                results.insert(*blob_id, memory.clone());
            } else {
                missing_ids.push(*blob_id);
            }
        }

        // Fetch missing blobs from external DB if any
        if !missing_ids.is_empty() {
            let encrypted_blobs = self.db_client.get_blobs(&missing_ids).await?;
            // Assuming get_blobs returns blobs in the same order as requested IDs
            for (blob_id, encrypted_blob) in missing_ids.iter().zip(encrypted_blobs.into_iter()) {
                let decrypted_data =
                    decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
                let memory: Memory = Memory::decode(&*decrypted_data)?;
                self.content_cache.insert(*blob_id, memory.clone());
                results.insert(*blob_id, memory);
            }
        }

        // Collect results in the original order
        Ok(blob_ids.iter().map(|id| results.remove(id).unwrap()).collect::<Vec<_>>())
    }

    pub async fn add_memory(&mut self, memory: Memory) -> anyhow::Result<BlobId> {
        let blob_id: BlobId = rand::rng().random();
        let memory_data = memory.encode_to_vec();
        let nonce = generate_nonce();
        let encrypted_data = encrypt(&self.dek, &nonce, &memory_data)?;
        let encrypted_blob = EncryptedDatablob { nonce, data: encrypted_data };

        // Store in external DB, explicitly providing the generated ID
        self.db_client.add_blob(encrypted_blob, Some(blob_id)).await?;

        // Add to local cache
        self.content_cache.insert(blob_id, memory);

        Ok(blob_id)
    }

    pub async fn add_memories(&mut self, memories: &[Memory]) -> anyhow::Result<Vec<BlobId>> {
        let mut blob_ids = Vec::with_capacity(memories.len());
        let mut encrypted_blobs = Vec::with_capacity(memories.len());

        for memory in memories {
            let blob_id: BlobId = rand::rng().random();
            let memory_data = memory.encode_to_vec();
            let nonce = generate_nonce();
            let encrypted_data = encrypt(&self.dek, &nonce, &memory_data)?;
            let encrypted_blob = EncryptedDatablob { nonce, data: encrypted_data };

            blob_ids.push(blob_id);
            encrypted_blobs.push(encrypted_blob);
        }

        // Store batch in external DB, explicitly providing the generated IDs
        self.db_client.add_blobs(encrypted_blobs, Some(blob_ids.clone())).await?;

        // Add to local cache
        for (blob_id, memory) in blob_ids.iter().zip(memories.iter()) {
            self.content_cache.insert(*blob_id, memory.clone());
        }

        Ok(blob_ids)
    }
}

/// A database with cache. It loads the meta database of the user at start,
/// then loads documents at request. The loaded documents will be then cached
/// in memory.
pub struct DatabaseWithCache {
    database: IcingMetaDatabase,
    pub cache: MemoryCache,
}

impl DatabaseWithCache {
    pub fn new(database: IcingMetaDatabase, dek: Vec<u8>, db_client: ExternalDbClient) -> Self {
        Self { database, cache: MemoryCache::new(db_client, dek) }
    }

    pub fn meta_db(&mut self) -> &mut IcingMetaDatabase {
        &mut self.database
    }
}

#[derive(Encode, Decode, PartialEq, Debug)]
pub struct EncryptedDatablob {
    pub nonce: Vec<u8>,
    pub data: Vec<u8>,
}

pub fn encrypt_database(
    database: &IcingMetaDatabase,
    key: &[u8],
) -> anyhow::Result<EncryptedDatablob> {
    let nonce = generate_nonce();
    let datablob = database.export();
    let data = encrypt(key, &nonce, &datablob)?;
    Ok(EncryptedDatablob { nonce, data })
}

pub fn decrypt_database(
    datablob: EncryptedDatablob,
    key: &[u8],
) -> anyhow::Result<IcingMetaDatabase> {
    let nonce = datablob.nonce;
    let data = datablob.data;
    let decrypted_data = decrypt(key, &nonce, &data)?;
    let meta_db = IcingMetaDatabase::import(&decrypted_data, None)?; // Import to a temp dir by default
    Ok(meta_db)
}

// Handlers for storing raw data blobs in the external database.
#[async_trait]
pub trait DataBlobHandler {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDatablob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId>;
    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDatablob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>>;
    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDatablob>;
    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDatablob>>;
}

#[async_trait]
impl DataBlobHandler for ExternalDbClient {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDatablob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId> {
        let id = id.unwrap_or_else(|| rand::rng().random::<i64>());
        let data_blob = DataBlob {
            id,
            encrypted_blob: bincode::encode_to_vec(&data_blob, config::standard())?,
        };
        let db_response = self
            .write_data_blob(WriteDataBlobRequest { data_blob: Some(data_blob) })
            .await
            .map_err(anyhow::Error::msg)?
            .into_inner();
        debug!("db response {:#?}", db_response);
        Ok(id)
    }

    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDatablob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>> {
        let mut result = Vec::with_capacity(data_blobs.len());
        let ids: Vec<Option<BlobId>> = if let Some(ids) = ids {
            ids.iter().map(|id| Some(*id)).collect()
        } else {
            vec![None; data_blobs.len()]
        };
        assert_eq!(data_blobs.len(), ids.len());
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch add.
        for (data_blob, id) in data_blobs.into_iter().zip(ids.into_iter()) {
            result.push(self.add_blob(data_blob, id).await?);
        }
        Ok(result)
    }

    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDatablob> {
        let db_response = self
            .read_data_blob(ReadDataBlobRequest { id: *id })
            .await
            .expect("Read blob fail!")
            .into_inner();
        if let Some(status) = db_response.status {
            if status.success && db_response.data_blob.is_some() {
                let data_blob = db_response.data_blob.unwrap();
                let (data_blob, _): (EncryptedDatablob, usize) =
                    bincode::decode_from_slice(&data_blob.encrypted_blob, config::standard())?;
                return Ok(data_blob);
            }
        }
        bail!("Failed to read data blob");
    }

    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDatablob>> {
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch get.
        let mut result = Vec::with_capacity(ids.len());
        for id in ids {
            let mut client = self.clone();
            let id = *id;
            result.push(tokio::spawn(async move { client.get_blob(&id).await.unwrap() }));
        }
        let result = futures::future::join_all(result).await;
        result.into_iter().map(|x| x.map_err(anyhow::Error::msg)).collect()
    }
}

#[cfg(test)]
mod tests {
    use googletest::prelude::*;
    use tempfile::tempdir;

    use super::*;

    #[gtest]
    fn basic_icing_search_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let mut icing_database = IcingMetaDatabase::new(temp_dir.path().to_str().unwrap())?;

        let mut memory = Memory::default();
        memory.id = "Thisisanid".to_string();
        memory.tags.push("the_tag".to_string());
        let blob_id = 12345;
        icing_database.add_memory(memory, blob_id)?;
        let mut memory2 = Memory::default();
        memory2.id = "Thisisanid2".to_string();
        memory2.tags.push("the_tag".to_string());
        let blob_id2 = 12346;
        icing_database.add_memory(memory2, blob_id2)?;

        let result = icing_database.get_memories_by_tag("the_tag".to_string()).unwrap();
        expect_that!(result, unordered_elements_are![eq(&blob_id), eq(&blob_id2)]);
        Ok(())
    }

    #[gtest]
    fn icing_import_export_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let base_dir = temp_dir.path().to_str().unwrap();
        let mut icing_database = IcingMetaDatabase::new(base_dir)?;

        let memory_id1 = "memory_id_export_1".to_string();
        let blob_id1 = 654321;
        let memory1 = Memory {
            id: memory_id1.clone(),
            tags: vec!["export_tag".to_string()],
            ..Default::default()
        };
        icing_database.add_memory(memory1, blob_id1)?;

        // Export the database
        let exported_data = icing_database.export();
        drop(icing_database); // Drop the original instance

        // Import into a new directory (or the same one after cleaning)
        let import_temp_dir = tempdir().unwrap();
        let import_base_dir = import_temp_dir.path().to_str().unwrap();
        let imported_database =
            IcingMetaDatabase::import(&exported_data, Some(import_base_dir)).unwrap();

        // Verify data exists in the imported database
        expect_that!(
            imported_database.get_blob_id_by_memory_id(memory_id1).unwrap(),
            eq(Some(blob_id1))
        );
        expect_that!(
            imported_database.get_memories_by_tag("export_tag".to_string()).unwrap(),
            unordered_elements_are![eq(&blob_id1)]
        );
        Ok(())
    }

    #[gtest]
    fn icing_get_blob_id_by_memory_id_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let mut icing_database = IcingMetaDatabase::new(temp_dir.path().to_str().unwrap())?;

        let memory_id1 = "memory_id_1".to_string();
        let blob_id1 = 54321;
        let memory1 =
            Memory { id: memory_id1.clone(), tags: vec!["tag1".to_string()], ..Default::default() };
        icing_database.add_memory(memory1, blob_id1)?;

        let memory_id2 = "memory_id_2".to_string();
        let blob_id2 = 54322;
        let memory2 =
            Memory { id: memory_id2.clone(), tags: vec!["tag2".to_string()], ..Default::default() };
        icing_database.add_memory(memory2, blob_id2)?;

        // Test finding an existing blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id(memory_id1).unwrap(),
            eq(Some(blob_id1))
        );
        // Test finding another existing blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id(memory_id2).unwrap(),
            eq(Some(blob_id2))
        );
        // Test finding a non-existent blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id("non_existent_id".to_string()).unwrap(),
            eq(None)
        );
        Ok(())
    }
}
