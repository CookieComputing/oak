//
// Copyright 2025 The Project Oak Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::collections::HashMap;

use anyhow::bail;
use async_trait::async_trait;
use rand::Rng;
use sealed_memory_grpc_proto::oak::private_memory::sealed_memory_database_service_client::SealedMemoryDatabaseServiceClient;
use sealed_memory_rust_proto::oak::private_memory::{
    DataBlob, Memory, ReadDataBlobRequest, WriteDataBlobRequest,
};
use tonic::transport::Channel;

use crate::{
    debug,
    encryption::{decrypt, encrypt, generate_nonce},
};
pub type ExternalDbClient = SealedMemoryDatabaseServiceClient<Channel>;
// The unique id for a opaque blob stored in the disk.
// TODO: b/413429146 - Use a larger int.
pub type BlobId = i64;

// The unique id for a memory, responding to `struct Memory`.
// It doesn't have a 1:1 mapping to BlobId, as a single memory
// might result in multiple blobs. For example, the raw content
// of a memory becomes a blob, while the meta data becomes another.
// The memory id is generated by the server and returned to clients
// at `add_memory` requests. Clients then can use this id to get the
// memory.
pub type MemoryId = String;

/// The essential database that stores all the meta information
/// except the raw document content of a user.
#[derive(Default, serde::Serialize, serde::Deserialize)]
pub struct MetaDatabase {
    inner: HashMap<MemoryId, BlobId>,
}

/// In memory cache for memories. When a memory is added, it is cached in
/// `MemoryCache` and also persisted at disk. When a memory is fetched, if the
/// memory is cached, it is returned directly from the cached. Otherwise, it
/// will further fetched from the external storage.
// TODO: b/412698203 - Add eviction to avoid OOM.
pub struct MemoryCache {
    db_client: ExternalDbClient,
    content_cache: HashMap<BlobId, Memory>,
    dek: Vec<u8>,
}

impl MemoryCache {
    pub fn new(db_client: ExternalDbClient, dek: Vec<u8>) -> Self {
        let content_cache = HashMap::<BlobId, Memory>::default();
        Self { db_client, dek, content_cache }
    }

    pub async fn get_memory_by_blob_id(&mut self, blob_id: &BlobId) -> anyhow::Result<Memory> {
        // Check cache first
        if let Some(memory) = self.content_cache.get(blob_id) {
            return Ok(memory.clone());
        }

        // If not in cache, fetch from external DB
        let encrypted_blob = self.db_client.get_blob(blob_id).await?;
        let decrypted_data = decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
        let memory: Memory = serde_json::from_slice(&decrypted_data)?;
        self.content_cache.insert(*blob_id, memory.clone());
        Ok(memory)
    }

    pub async fn get_memories_by_blob_ids(
        &mut self,
        blob_ids: &[BlobId],
    ) -> anyhow::Result<Vec<Memory>> {
        let mut results: HashMap<BlobId, Memory> = HashMap::with_capacity(blob_ids.len());
        let mut missing_ids: Vec<BlobId> = Vec::new();

        // Check cache first
        for blob_id in blob_ids {
            if let Some(memory) = self.content_cache.get(blob_id) {
                results.insert(*blob_id, memory.clone());
            } else {
                missing_ids.push(*blob_id);
            }
        }

        // Fetch missing blobs from external DB if any
        if !missing_ids.is_empty() {
            let encrypted_blobs = self.db_client.get_blobs(&missing_ids).await?;
            // Assuming get_blobs returns blobs in the same order as requested IDs
            for (blob_id, encrypted_blob) in missing_ids.iter().zip(encrypted_blobs.into_iter()) {
                let decrypted_data =
                    decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
                let memory: Memory = serde_json::from_slice(&decrypted_data)?;
                self.content_cache.insert(*blob_id, memory.clone());
                results.insert(*blob_id, memory);
            }
        }

        // Collect results in the original order
        Ok(blob_ids.iter().map(|id| results.remove(id).unwrap()).collect::<Vec<_>>())
    }

    pub async fn add_memory(&mut self, memory: Memory) -> anyhow::Result<BlobId> {
        let blob_id: BlobId = rand::rng().random();
        let memory_data = serde_json::to_vec(&memory)?;
        let nonce = generate_nonce();
        let encrypted_data = encrypt(&self.dek, &nonce, &memory_data)?;
        let encrypted_blob = EncryptedDatablob { nonce, data: encrypted_data };

        // Store in external DB, explicitly providing the generated ID
        self.db_client.add_blob(encrypted_blob, Some(blob_id)).await?;

        // Add to local cache
        self.content_cache.insert(blob_id, memory);

        Ok(blob_id)
    }

    pub async fn add_memories(&mut self, memories: &[Memory]) -> anyhow::Result<Vec<BlobId>> {
        let mut blob_ids = Vec::with_capacity(memories.len());
        let mut encrypted_blobs = Vec::with_capacity(memories.len());

        for memory in memories {
            let blob_id: BlobId = rand::rng().random();
            let memory_data = serde_json::to_vec(memory)?;
            let nonce = generate_nonce();
            let encrypted_data = encrypt(&self.dek, &nonce, &memory_data)?;
            let encrypted_blob = EncryptedDatablob { nonce, data: encrypted_data };

            blob_ids.push(blob_id);
            encrypted_blobs.push(encrypted_blob);
        }

        // Store batch in external DB, explicitly providing the generated IDs
        self.db_client.add_blobs(encrypted_blobs, Some(blob_ids.clone())).await?;

        // Add to local cache
        for (blob_id, memory) in blob_ids.iter().zip(memories.iter()) {
            self.content_cache.insert(*blob_id, memory.clone());
        }

        Ok(blob_ids)
    }
}

/// A database with cache. It loads the meta database of the user at start,
/// then loads documents at request. The loaded documents will be then cached
/// in memory.
pub struct DatabaseWithCache {
    database: MetaDatabase,
    pub cache: MemoryCache,
}

impl DatabaseWithCache {
    pub fn new(database: MetaDatabase, dek: Vec<u8>, db_client: ExternalDbClient) -> Self {
        Self { database, cache: MemoryCache::new(db_client, dek) }
    }

    pub fn meta_db(&mut self) -> &mut MetaDatabase {
        &mut self.database
    }
}

impl MetaDatabase {
    pub fn all_blob_ids(&self) -> Vec<BlobId> {
        self.inner.values().cloned().collect()
    }
    pub fn add_memory(&mut self, id: MemoryId, blob_id: BlobId) -> bool {
        self.inner.insert(id, blob_id).is_none()
    }

    pub fn get_blob_id_by_memory_id(&self, id: MemoryId) -> Option<BlobId> {
        self.inner.get(&id).cloned()
    }

    pub fn reset(&mut self) {
        self.inner.clear();
    }
}

#[derive(serde::Serialize, serde::Deserialize)]
pub struct EncryptedDatablob {
    pub nonce: Vec<u8>,
    pub data: Vec<u8>,
}

pub fn encrypt_database(database: &MetaDatabase, key: &[u8]) -> anyhow::Result<EncryptedDatablob> {
    let nonce = generate_nonce();
    let datablob = serde_json::to_vec(database)?;
    let data = encrypt(key, &nonce, &datablob)?;
    Ok(EncryptedDatablob { nonce, data })
}

pub fn decrypt_database(datablob: EncryptedDatablob, key: &[u8]) -> anyhow::Result<MetaDatabase> {
    let nonce = datablob.nonce;
    let data = datablob.data;
    let decrypted_data = decrypt(key, &nonce, &data)?;
    Ok(serde_json::from_slice::<MetaDatabase>(&decrypted_data)?)
}

// Handlers for storing raw data blobs in the external database.
#[async_trait]
pub trait DataBlobHandler {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDatablob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId>;
    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDatablob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>>;
    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDatablob>;
    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDatablob>>;
}

#[async_trait]
impl DataBlobHandler for ExternalDbClient {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDatablob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId> {
        let id = id.unwrap_or_else(|| rand::rng().random::<i64>());
        let data_blob = DataBlob { id, encrypted_blob: serde_json::to_vec(&data_blob)? };
        let db_response = self
            .write_data_blob(WriteDataBlobRequest { data_blob: Some(data_blob) })
            .await
            .map_err(anyhow::Error::msg)?
            .into_inner();
        debug!("db response {:#?}", db_response);
        Ok(id)
    }

    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDatablob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>> {
        let mut result = Vec::with_capacity(data_blobs.len());
        let ids: Vec<Option<BlobId>> = if let Some(ids) = ids {
            ids.iter().map(|id| Some(*id)).collect()
        } else {
            vec![None; data_blobs.len()]
        };
        assert_eq!(data_blobs.len(), ids.len());
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch add.
        for (data_blob, id) in data_blobs.into_iter().zip(ids.into_iter()) {
            result.push(self.add_blob(data_blob, id).await?);
        }
        Ok(result)
    }

    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDatablob> {
        let db_response = self
            .read_data_blob(ReadDataBlobRequest { id: *id })
            .await
            .expect("Read blob fail!")
            .into_inner();
        if let Some(status) = db_response.status {
            if status.success && db_response.data_blob.is_some() {
                let data_blob = db_response.data_blob.unwrap();
                return Ok(serde_json::from_slice::<EncryptedDatablob>(&data_blob.encrypted_blob)?);
            }
        }
        bail!("Failed to read data blob");
    }

    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDatablob>> {
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch get.
        let mut result = Vec::with_capacity(ids.len());
        for id in ids {
            result.push(self.get_blob(id).await?)
        }
        Ok(result)
    }
}
