//
// Copyright 2025 The Project Oak Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
use std::collections::HashMap;

use anyhow::{bail, ensure};
use async_trait::async_trait;
use icing::IcingGroundTruthFilesHelper;
use prost::Message;
use rand::Rng;
use sealed_memory_grpc_proto::oak::private_memory::sealed_memory_database_service_client::SealedMemoryDatabaseServiceClient;
use sealed_memory_rust_proto::oak::private_memory::{
    DataBlob, Embedding, EncryptedDataBlob, Memory, ReadDataBlobRequest, WriteDataBlobRequest,
};
use tempfile::tempdir;
use tonic::transport::Channel;

use crate::{
    debug,
    encryption::{decrypt, encrypt, generate_nonce},
};
pub type ExternalDbClient = SealedMemoryDatabaseServiceClient<Channel>;
// The unique id for a opaque blob stored in the disk.
// TODO: b/413429146 - Use a larger int.
pub type BlobId = i64;

// The unique id for a memory, responding to `struct Memory`.
// It doesn't have a 1:1 mapping to BlobId, as a single memory
// might result in multiple blobs. For example, the raw content
// of a memory becomes a blob, while the meta data becomes another.
// The memory id is generated by the server and returned to clients
// at `add_memory` requests. Clients then can use this id to get the
// memory.
pub type MemoryId = String;

/// The essential database that stores all the meta information
/// except the raw document content of a user.
///
/// The current schema is
/// {
///   "memory_id": string, indexable
///   "tags": repeated string, indexable
///   "blob_id": string
/// }
/// Indexable fields are the ones that can be searched against.
pub struct IcingMetaDatabase {
    icing_search_engine: cxx::UniquePtr<icing::IcingSearchEngine>,
    base_dir: String,
}

// `IcingMetaBase` is safe to send because it is behind a unique_ptr,
// but it is unsafe to sync because that will allow concurrent write accesses
// to the underlying icing database.
unsafe impl Send for IcingMetaDatabase {}
impl !Sync for IcingMetaDatabase {}

const NAMESPACE_NAME: &str = "namespace";
const SCHMA_NAME: &str = "Memory";
const TAG_NAME: &str = "tag";
const MEMORY_ID_NAME: &str = "memoryId";
const BLOB_ID_NAME: &str = "blobId";
const EMBEDDING_NAME: &str = "embedding";

impl IcingMetaDatabase {
    /// Creates a ResultSpecProto projection to retrieve only the blob ids.
    fn create_blob_id_projection() -> icing::TypePropertyMask {
        icing::TypePropertyMask {
            schema_type: Some(SCHMA_NAME.to_string()),
            paths: vec![BLOB_ID_NAME.to_string()],
        }
    }

    fn extract_blob_ids_from_search_result(search_result: icing::SearchResultProto) -> Vec<BlobId> {
        search_result.results.iter().filter_map(Self::extract_blob_id_from_doc).collect::<Vec<_>>()
    }

    fn create_search_filter(path: &str) -> icing::TypePropertyMask {
        icing::TypePropertyMask {
            schema_type: Some(SCHMA_NAME.to_string()),
            paths: vec![path.to_string()],
        }
    }
    pub fn base_dir(&self) -> String {
        self.base_dir.clone()
    }

    /// Rebuild the icing database in `target_base_dir` given the content of the
    /// ground truth files in `buffer`.
    pub fn import(buffer: &[u8], target_base_dir: Option<&str>) -> anyhow::Result<Self> {
        let base_dir_str = match target_base_dir {
            Some(dir) => dir.to_string(),
            _ => {
                let temp_dir = tempdir()?;
                temp_dir.path().to_str().unwrap().to_string()
            }
        };

        // Decode the ground truth data
        let ground_truth = icing::IcingGroundTruthFiles::decode(buffer)?;

        // Migrate the data to the target directory (this handles cleaning the
        // directory)
        ground_truth.migrate(&base_dir_str)?;

        // Initialize Icing Search Engine from the migrated directory
        let options_bytes = icing::get_default_icing_options(&base_dir_str).encode_to_vec();
        let icing_search_engine = icing::create_icing_search_engine(&options_bytes);
        let result_proto = icing_search_engine.initialize();
        if result_proto.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into()) {
            bail!("Failed to initialize Icing engine after import: {:?}", result_proto.status);
        }

        Ok(Self { icing_search_engine, base_dir: base_dir_str })
    }

    /// Create a new icing database in `base_dir`. If there is already a icing
    /// db in `base_dir`, the old one will be deleted.
    pub fn new(base_dir: &str) -> anyhow::Result<Self> {
        let schema_type_builder = icing::create_schema_type_config_builder();
        schema_type_builder
            .set_type(SCHMA_NAME.as_bytes())
            .add_property(
                icing::create_property_config_builder()
                    .set_name(TAG_NAME.as_bytes())
                    .set_data_type_string(
                        icing::term_match_type::Code::ExactOnly.into(),
                        icing::string_indexing_config::tokenizer_type::Code::Plain.into(),
                    )
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Repeated.into(),
                    ),
            )
            .add_property(
                icing::create_property_config_builder()
                    .set_name(MEMORY_ID_NAME.as_bytes())
                    .set_data_type_string(
                        icing::term_match_type::Code::ExactOnly.into(),
                        icing::string_indexing_config::tokenizer_type::Code::Plain.into(),
                    )
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Optional.into(),
                    ),
            )
            .add_property(
                icing::create_property_config_builder()
                    .set_name(BLOB_ID_NAME.as_bytes())
                    // We don't need to index blob id
                    .set_data_type(icing::property_config_proto::data_type::Code::Int64.into())
                    .set_cardinality(
                        icing::property_config_proto::cardinality::Code::Optional.into(),
                    ),
            ).add_property(
                icing::create_property_config_builder()
                    .set_name(EMBEDDING_NAME.as_bytes())
                    .set_data_type_vector(
                        icing::embedding_indexing_config::embedding_indexing_type::Code::LinearSearch.into(),
                    )
                    .set_cardinality(icing::property_config_proto::cardinality::Code::Repeated.into())
            );

        let schema_builder = icing::create_schema_builder();
        schema_builder.add_type(&schema_type_builder);
        let schema = schema_builder.build();

        let options_bytes = icing::get_default_icing_options(base_dir).encode_to_vec();
        let icing_search_engine = icing::create_icing_search_engine(&options_bytes);
        let result_proto = icing_search_engine.initialize();
        ensure!(result_proto.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));

        let result_proto = icing_search_engine.set_schema(&schema);
        ensure!(result_proto.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));

        Ok(Self { icing_search_engine, base_dir: base_dir.to_string() })
    }

    pub fn add_memory(&mut self, memory: Memory, blob_id: BlobId) -> anyhow::Result<()> {
        let memory_id = memory.id;
        let tags: Vec<&[u8]> = memory.tags.iter().map(|x| x.as_bytes()).collect();
        let embeddings: Vec<_> = memory
            .embeddings
            .iter()
            .map(|x| icing::create_vector_proto(x.model_signature.as_str(), &x.values))
            .collect();
        let doc = icing::create_document_builder()
            .set_key(NAMESPACE_NAME.as_bytes(), memory_id.as_bytes())
            .set_schema(SCHMA_NAME.as_bytes())
            .add_string_property(TAG_NAME.as_bytes(), &tags)
            .add_string_property(MEMORY_ID_NAME.as_bytes(), &[memory_id.as_bytes()])
            .add_int64_property(BLOB_ID_NAME.as_bytes(), blob_id)
            .add_vector_property(EMBEDDING_NAME.as_bytes(), &embeddings)
            .build();
        let result = self.icing_search_engine.put(&doc);
        if result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into()) {
            debug!("{:?}", result);
        }
        ensure!(result.status.unwrap().code == Some(icing::status_proto::Code::Ok.into()));
        Ok(())
    }

    pub fn get_memories_by_tag(&self, tag: String) -> anyhow::Result<Vec<BlobId>> {
        let search_spec = icing::SearchSpecProto {
            query: Some(tag),
            // Match exactly as defined in the schema for tags.
            term_match_type: Some(icing::term_match_type::Code::ExactOnly.into()),
            type_property_filters: vec![Self::create_search_filter(TAG_NAME)],
            ..Default::default()
        };

        let result_spec = icing::ResultSpecProto {
            // Request a large number to get all results in one go for simplicity.
            // Consider pagination for very large datasets.
            num_per_page: Some(1000),
            type_property_masks: vec![Self::create_blob_id_projection()],
            ..Default::default()
        };

        let search_result: icing::SearchResultProto = self.icing_search_engine.search(
            &search_spec,
            &icing::get_default_scoring_spec(), // Use default scoring for now
            &result_spec,
        );

        if search_result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into())
        {
            bail!("Icing search failed: {:?}", search_result.status);
        }

        Ok(Self::extract_blob_ids_from_search_result(search_result))
    }

    pub fn get_blob_id_by_memory_id(&self, memory_id: MemoryId) -> anyhow::Result<Option<BlobId>> {
        let search_spec = icing::SearchSpecProto {
            query: Some(memory_id.to_string()),
            term_match_type: Some(icing::term_match_type::Code::ExactOnly.into()),
            type_property_filters: vec![Self::create_search_filter(MEMORY_ID_NAME)],
            ..Default::default()
        };

        let result_spec = icing::ResultSpecProto {
            num_per_page: Some(1), // We expect at most one result
            type_property_masks: vec![Self::create_blob_id_projection()],
            ..Default::default()
        };

        let search_result: icing::SearchResultProto = self.icing_search_engine.search(
            &search_spec,
            &icing::get_default_scoring_spec(), // Scoring doesn't matter much here
            &result_spec,
        );

        if search_result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into())
        {
            bail!("Icing search failed for memory_id {}: {:?}", memory_id, search_result.status);
        }

        // Extract the blob_id (int64) from the first result, if any
        Ok(search_result.results.first().and_then(Self::extract_blob_id_from_doc))
    }

    fn extract_blob_id_from_doc(
        doc_hit: &icing::search_result_proto::ResultProto,
    ) -> Option<BlobId> {
        let blob_id_name = BLOB_ID_NAME.to_string();
        doc_hit
            .document
            .as_ref()?
            .properties
            .iter()
            .find(|prop| prop.name.as_ref() == Some(&blob_id_name))?
            .int64_values
            .first()
            .cloned()
    }

    pub fn export(&self) -> Vec<u8> {
        self.icing_search_engine.persist_to_disk(icing::persist_type::Code::Full.into());
        let blob = icing::IcingGroundTruthFiles::new(&self.base_dir)
            .expect("Failed to read ground truth files from base_dir")
            .encode_to_vec();
        debug!("Exporting icing db, len: {}", blob.len());
        blob
    }

    pub fn reset(&self) {
        self.icing_search_engine.reset();
    }

    /// Search based on the document embedding `doc_embedding` (the ones that
    /// users set when adding the memory) and search embedding
    /// `search_embedding` (the one that set at search memory request).
    /// The process is as follow:
    /// 1. For each memory, we find all the document embeddings that matches the
    ///    name of the search embedding, say `[doc_embeding1, doc_embedding2,
    ///    ...]`.
    /// 2. Perform a dot product on `search_embedding` and the matched
    ///    `[doc1_embedding, ...]`, which gives a list of scores `[score1,
    ///    score2, ...]`.
    /// 3. Sum the scores, and the corresponding memory has the final score
    ///    `score_sum`.
    /// 4. We repeat 1-3 for all memories, rank the memories by `score_sum`, and
    ///    return the first `limit` ones with highest scores.
    pub fn embedding_search(
        &self,
        embedding: &[Embedding],
        limit: u32,
    ) -> anyhow::Result<(Vec<BlobId>, Vec<f32>)> {
        let mut scoring_spec = icing::get_default_scoring_spec();
        scoring_spec.rank_by = Some(
            icing::scoring_spec_proto::ranking_strategy::Code::AdvancedScoringExpression.into(),
        );

        // Caculate the sum of the scores of all matching embeddings.
        const SUM_ALL_MATCHING_EMBEDDING: &str =
            "sum(this.matchedSemanticScores(getEmbeddingParameter(0)))";
        scoring_spec.advanced_scoring_expression = Some(SUM_ALL_MATCHING_EMBEDDING.to_string());

        let search_spec = icing::SearchSpecProto {
            term_match_type: Some(icing::term_match_type::Code::ExactOnly.into()),
            embedding_query_metric_type: Some(
                icing::search_spec_proto::embedding_query_metric_type::Code::DotProduct.into(),
            ),

            embedding_query_vectors: embedding
                .iter()
                .map(|x| icing::create_vector_proto(x.model_signature.as_str(), &x.values))
                .collect(),

            // Search the first embedding property, specified by `EMBEDDING_NAME`.
            // Since we have only one embedding property, this is the one to go.
            query: Some("semanticSearch(getEmbeddingParameter(0))".to_string()),
            enabled_features: vec![icing::LIST_FILTER_QUERY_LANGUAGE_FEATURE.to_string()],
            ..Default::default()
        };

        let mut result_spec = icing::ResultSpecProto {
            num_per_page: Some(limit.try_into().unwrap()),
            ..Default::default()
        };

        // We only need the `BlobId`.
        result_spec.type_property_masks.push(Self::create_blob_id_projection());
        let search_result: icing::SearchResultProto =
            self.icing_search_engine.search(&search_spec, &scoring_spec, &result_spec);

        if search_result.status.clone().unwrap().code != Some(icing::status_proto::Code::Ok.into())
        {
            bail!("Icing search failed for {:?}", search_result.status);
        }

        let scores: Vec<f32> =
            search_result.results.iter().map(|x| x.score.unwrap() as _).collect();
        let blob_ids = Self::extract_blob_ids_from_search_result(search_result);
        ensure!(blob_ids.len() == scores.len());
        Ok((blob_ids, scores))
    }
}

impl Drop for IcingMetaDatabase {
    fn drop(&mut self) {
        match std::fs::remove_dir_all(&self.base_dir) {
            Ok(()) => debug!("Successfully removed the icing directory."),
            Err(e) => debug!("Failed to remove the icing directory, {}", e),
        }
    }
}

/// In memory cache for memories.
///
/// When a memory is added, it is cached in `MemoryCache` and also persisted at
/// disk. When a memory is fetched, if the memory is cached, it is returned
/// directly from the cached. Otherwise, it will further fetched from the
/// external storage.
/// TODO: b/412698203 - Add eviction to avoid OOM.
pub struct MemoryCache {
    db_client: ExternalDbClient,
    content_cache: HashMap<BlobId, Memory>,
    dek: Vec<u8>,
}

impl MemoryCache {
    pub fn new(db_client: ExternalDbClient, dek: Vec<u8>) -> Self {
        let content_cache = HashMap::<BlobId, Memory>::default();
        Self { db_client, dek, content_cache }
    }

    async fn fetch_decrypt_decode_memory(&self, blob_id: &BlobId) -> anyhow::Result<Memory> {
        let encrypted_blob = self.db_client.clone().get_blob(blob_id).await?;
        let decrypted_data = decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
        Ok(Memory::decode(&*decrypted_data)?)
    }

    pub async fn get_memory_by_blob_id(&mut self, blob_id: &BlobId) -> anyhow::Result<Memory> {
        // Check cache first
        if let Some(memory) = self.content_cache.get(blob_id) {
            return Ok(memory.clone());
        }
        // If not in cache, fetch from external DB
        let memory = self.fetch_decrypt_decode_memory(blob_id).await?;
        self.content_cache.insert(*blob_id, memory.clone());
        Ok(memory)
    }

    pub async fn get_memories_by_blob_ids(
        &mut self,
        blob_ids: &[BlobId],
    ) -> anyhow::Result<Vec<Memory>> {
        let mut results: HashMap<BlobId, Memory> = HashMap::with_capacity(blob_ids.len());
        let mut missing_ids: Vec<BlobId> = Vec::new();

        // Check cache first
        for blob_id in blob_ids {
            if let Some(memory) = self.content_cache.get(blob_id) {
                results.insert(*blob_id, memory.clone());
            } else {
                missing_ids.push(*blob_id);
            }
        }

        // Fetch missing blobs from external DB if any
        if !missing_ids.is_empty() {
            let encrypted_blobs = self.db_client.get_blobs(&missing_ids).await?;
            for (blob_id, encrypted_blob) in missing_ids.iter().zip(encrypted_blobs.into_iter()) {
                let decrypted_data =
                    decrypt(&self.dek, &encrypted_blob.nonce, &encrypted_blob.data)?;
                let memory: Memory = Memory::decode(&*decrypted_data)?;
                self.content_cache.insert(*blob_id, memory.clone());
                results.insert(*blob_id, memory);
            }
        }

        // Collect results in the original order
        Ok(blob_ids.iter().map(|id| results.remove(id).unwrap()).collect::<Vec<_>>())
    }

    /// Encodes and encrypts a memory, returning the blob and a generated nonce.
    fn encode_encrypt_memory(&self, memory: &Memory) -> anyhow::Result<(Vec<u8>, Vec<u8>)> {
        let memory_data = memory.encode_to_vec();
        let nonce = generate_nonce();
        let encrypted_data = encrypt(&self.dek, &nonce, &memory_data)?;
        Ok((encrypted_data, nonce))
    }

    pub async fn add_memory(&mut self, memory: Memory) -> anyhow::Result<BlobId> {
        let blob_id: BlobId = rand::rng().random();
        let (encrypted_data, nonce) = self.encode_encrypt_memory(&memory)?;
        let encrypted_blob = EncryptedDataBlob { nonce, data: encrypted_data };

        // Store in external DB, explicitly providing the generated ID
        self.db_client.add_blob(encrypted_blob, Some(blob_id)).await?;

        // Add to local cache
        self.content_cache.insert(blob_id, memory);

        Ok(blob_id)
    }

    pub async fn add_memories(&mut self, memories: &[Memory]) -> anyhow::Result<Vec<BlobId>> {
        let mut blob_ids = Vec::with_capacity(memories.len());
        let mut encrypted_blobs = Vec::with_capacity(memories.len());

        for memory in memories {
            let (encrypted_data, nonce) = self.encode_encrypt_memory(memory)?;
            let blob_id: BlobId = rand::rng().random();
            let encrypted_blob = EncryptedDataBlob { nonce, data: encrypted_data };

            blob_ids.push(blob_id);
            encrypted_blobs.push(encrypted_blob);
        }

        // Store batch in external DB, explicitly providing the generated IDs
        self.db_client.add_blobs(encrypted_blobs, Some(blob_ids.clone())).await?;

        // Add to local cache
        for (blob_id, memory) in blob_ids.iter().zip(memories.iter()) {
            self.content_cache.insert(*blob_id, memory.clone());
        }

        Ok(blob_ids)
    }
}

/// A database with cache. It loads the meta database of the user at start,
/// then loads documents at request. The loaded documents will be then cached
/// in memory.
pub struct DatabaseWithCache {
    database: IcingMetaDatabase,
    pub cache: MemoryCache,
}

impl DatabaseWithCache {
    pub fn new(database: IcingMetaDatabase, dek: Vec<u8>, db_client: ExternalDbClient) -> Self {
        Self { database, cache: MemoryCache::new(db_client, dek) }
    }

    pub fn meta_db(&mut self) -> &mut IcingMetaDatabase {
        &mut self.database
    }
}

pub fn encrypt_database(
    database: &IcingMetaDatabase,
    key: &[u8],
) -> anyhow::Result<EncryptedDataBlob> {
    let nonce = generate_nonce();
    let datablob = database.export();
    let data = encrypt(key, &nonce, &datablob)?;
    Ok(EncryptedDataBlob { nonce, data })
}

pub fn decrypt_database(
    datablob: EncryptedDataBlob,
    key: &[u8],
) -> anyhow::Result<IcingMetaDatabase> {
    let nonce = datablob.nonce;
    let data = datablob.data;
    let decrypted_data = decrypt(key, &nonce, &data)?;
    let meta_db = IcingMetaDatabase::import(&decrypted_data, None)?; // Import to a temp dir by default
    Ok(meta_db)
}

// Handlers for storing raw data blobs in the external database.
#[async_trait]
pub trait DataBlobHandler {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDataBlob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId>;
    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDataBlob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>>;
    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDataBlob>;
    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDataBlob>>;
}

#[async_trait]
impl DataBlobHandler for ExternalDbClient {
    async fn add_blob(
        &mut self,
        data_blob: EncryptedDataBlob,
        id: Option<BlobId>,
    ) -> anyhow::Result<BlobId> {
        let id = id.unwrap_or_else(|| rand::rng().random::<i64>());
        let data_blob = DataBlob { id, encrypted_blob: data_blob.encode_to_vec() };
        let db_response = self
            .write_data_blob(WriteDataBlobRequest { data_blob: Some(data_blob) })
            .await
            .map_err(anyhow::Error::msg)?
            .into_inner();
        debug!("db response {:#?}", db_response);
        Ok(id)
    }

    async fn add_blobs(
        &mut self,
        data_blobs: Vec<EncryptedDataBlob>,
        ids: Option<Vec<BlobId>>,
    ) -> anyhow::Result<Vec<BlobId>> {
        let mut result = Vec::with_capacity(data_blobs.len());
        let ids: Vec<Option<BlobId>> = if let Some(ids) = ids {
            ids.iter().map(|id| Some(*id)).collect()
        } else {
            vec![None; data_blobs.len()]
        };
        assert_eq!(data_blobs.len(), ids.len());
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch add.
        for (data_blob, id) in data_blobs.into_iter().zip(ids.into_iter()) {
            result.push(self.add_blob(data_blob, id).await?);
        }
        Ok(result)
    }

    async fn get_blob(&mut self, id: &BlobId) -> anyhow::Result<EncryptedDataBlob> {
        let db_response = self
            .read_data_blob(ReadDataBlobRequest { id: *id })
            .await
            .expect("Read blob fail!")
            .into_inner();
        if let Some(status) = db_response.status {
            if status.success && db_response.data_blob.is_some() {
                let data_blob = db_response.data_blob.unwrap();
                let data_blob = EncryptedDataBlob::decode(&*data_blob.encrypted_blob)?;
                return Ok(data_blob);
            }
        }
        bail!("Failed to read data blob");
    }

    async fn get_blobs(&mut self, ids: &[BlobId]) -> anyhow::Result<Vec<EncryptedDataBlob>> {
        // TOOD: b/412698203 - Ideally we should have a rpc call that does batch get.
        let mut result = Vec::with_capacity(ids.len());
        for id in ids {
            let mut client = self.clone();
            let id = *id;
            result.push(tokio::spawn(async move { client.get_blob(&id).await.unwrap() }));
        }
        let result = futures::future::join_all(result).await;
        result.into_iter().map(|x| x.map_err(anyhow::Error::msg)).collect()
    }
}

#[cfg(test)]
mod tests {
    use googletest::prelude::*;
    use tempfile::tempdir;

    use super::*;

    #[gtest]
    fn basic_icing_search_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let mut icing_database = IcingMetaDatabase::new(temp_dir.path().to_str().unwrap())?;

        let memory = Memory {
            id: "Thisisanid".to_string(),
            tags: vec!["the_tag".to_string()],
            ..Default::default()
        };
        let blob_id = 12345;
        icing_database.add_memory(memory, blob_id)?;
        let memory2 = Memory {
            id: "Thisisanid2".to_string(),
            tags: vec!["the_tag".to_string()],
            ..Default::default()
        };
        let blob_id2 = 12346;
        icing_database.add_memory(memory2, blob_id2)?;

        let result = icing_database.get_memories_by_tag("the_tag".to_string()).unwrap();
        expect_that!(result, unordered_elements_are![eq(&blob_id), eq(&blob_id2)]);
        Ok(())
    }

    #[gtest]
    fn icing_import_export_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let base_dir = temp_dir.path().to_str().unwrap();
        let mut icing_database = IcingMetaDatabase::new(base_dir)?;

        let memory_id1 = "memory_id_export_1".to_string();
        let blob_id1 = 654321;
        let memory1 = Memory {
            id: memory_id1.clone(),
            tags: vec!["export_tag".to_string()],
            ..Default::default()
        };
        icing_database.add_memory(memory1, blob_id1)?;

        // Export the database
        let exported_data = icing_database.export();
        let base_dir_str = icing_database.base_dir();
        let base_dir = std::path::Path::new(&base_dir_str);
        drop(icing_database); // Drop the original instance
        expect_false!(base_dir.exists());

        // Import into a new directory (or the same one after cleaning)
        let import_temp_dir = tempdir().unwrap();
        let import_base_dir = import_temp_dir.path().to_str().unwrap();
        let imported_database =
            IcingMetaDatabase::import(&exported_data, Some(import_base_dir)).unwrap();

        // Verify data exists in the imported database
        expect_that!(
            imported_database.get_blob_id_by_memory_id(memory_id1).unwrap(),
            eq(Some(blob_id1))
        );
        expect_that!(
            imported_database.get_memories_by_tag("export_tag".to_string()).unwrap(),
            unordered_elements_are![eq(&blob_id1)]
        );
        Ok(())
    }

    #[gtest]
    fn icing_get_blob_id_by_memory_id_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let mut icing_database = IcingMetaDatabase::new(temp_dir.path().to_str().unwrap())?;

        let memory_id1 = "memory_id_1".to_string();
        let blob_id1 = 54321;
        let memory1 =
            Memory { id: memory_id1.clone(), tags: vec!["tag1".to_string()], ..Default::default() };
        icing_database.add_memory(memory1, blob_id1)?;

        let memory_id2 = "memory_id_2".to_string();
        let blob_id2 = 54322;
        let memory2 =
            Memory { id: memory_id2.clone(), tags: vec!["tag2".to_string()], ..Default::default() };
        icing_database.add_memory(memory2, blob_id2)?;

        // Test finding an existing blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id(memory_id1).unwrap(),
            eq(Some(blob_id1))
        );
        // Test finding another existing blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id(memory_id2).unwrap(),
            eq(Some(blob_id2))
        );
        // Test finding a non-existent blob ID
        expect_that!(
            icing_database.get_blob_id_by_memory_id("non_existent_id".to_string()).unwrap(),
            eq(None)
        );
        Ok(())
    }

    #[gtest]
    fn icing_embedding_search_test() -> anyhow::Result<()> {
        let temp_dir = tempdir().unwrap();
        let mut icing_database = IcingMetaDatabase::new(temp_dir.path().to_str().unwrap())?;

        let memory_id1 = "memory_embed_1".to_string();
        let blob_id1 = 98765;
        let embedding1 = Embedding {
            model_signature: "test_model".to_string(),
            values: vec![1.0, 0.0, 0.0], // Vector pointing along x-axis
        };
        let memory1 = Memory {
            id: memory_id1.clone(),
            tags: vec!["embed_tag".to_string()],
            embeddings: vec![embedding1.clone()],
            ..Default::default()
        };
        icing_database.add_memory(memory1, blob_id1)?;

        let memory_id2 = "memory_embed_2".to_string();
        let blob_id2 = 98766;
        let embedding2 = Embedding {
            model_signature: "test_model".to_string(),
            values: vec![0.0, 1.0, 0.0], // Vector pointing along y-axis
        };
        let memory2 = Memory {
            id: memory_id2.clone(),
            tags: vec!["embed_tag".to_string()],
            embeddings: vec![embedding2.clone()],
            ..Default::default()
        };
        icing_database.add_memory(memory2, blob_id2)?;

        // Query embedding close to embedding1
        let query_embedding =
            Embedding { model_signature: "test_model".to_string(), values: vec![0.9, 0.1, 0.0] };
        let (blob_ids, scores) = icing_database.embedding_search(&[query_embedding.clone()], 2)?;

        // Expect memory1 (blob_id1) to be the top result due to higher dot product
        expect_that!(blob_ids, elements_are![eq(&blob_id1), eq(&blob_id2)]);
        // We could also assert on the score if needed, but ordering is often sufficient
        expect_that!(scores, elements_are![eq(&0.9), eq(&0.1)]);

        // Make sure the limit works
        let (blob_ids, scores) = icing_database.embedding_search(&[query_embedding], 1)?;
        // Expect memory1 (blob_id1) to be the top result due to higher dot product
        expect_that!(blob_ids, elements_are![eq(&blob_id1)]);
        // We could also assert on the score if needed, but ordering is often sufficient
        expect_that!(scores.len(), eq(1));
        Ok(())
    }
}
